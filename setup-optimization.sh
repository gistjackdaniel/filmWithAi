#!/bin/bash

# SceneForge ì„±ëŠ¥ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# ë¡œê·¸ í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ì„¤ì •
PROJECT_DIR="/var/www/sceneforge"

log_info "âš¡ SceneForge ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì‹œìž‘..."

# 1. CDN ì„¤ì • (CloudFront)
log_info "â˜ï¸ CDN ì„¤ì • ì¤‘..."

# CloudFront ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > $PROJECT_DIR/setup-cloudfront.sh << 'EOF'
#!/bin/bash

# CloudFront ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# AWS CLIê°€ ì„¤ì¹˜ë˜ì–´ ìžˆì–´ì•¼ í•©ë‹ˆë‹¤

DOMAIN="your-domain.com"
S3_BUCKET="sceneforge-static-assets"

echo "CloudFront ë°°í¬ë¥¼ ìœ„í•œ ì„¤ì •..."
echo "1. S3 ë²„í‚· ìƒì„±: $S3_BUCKET"
echo "2. CloudFront ë°°í¬ ìƒì„±"
echo "3. ë„ë©”ì¸ ì—°ê²°"

# S3 ë²„í‚· ìƒì„± (ì •ì  ìžì‚°ìš©)
aws s3 mb s3://$S3_BUCKET --region us-east-1

# ì •ì  ìžì‚° ì—…ë¡œë“œ
aws s3 sync /var/www/sceneforge/dist s3://$S3_BUCKET --delete

# CloudFront ë°°í¬ ìƒì„±
aws cloudfront create-distribution \
    --origin-domain-name $S3_BUCKET.s3.amazonaws.com \
    --default-root-object index.html \
    --aliases $DOMAIN

echo "CloudFront ë°°í¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
EOF

chmod +x $PROJECT_DIR/setup-cloudfront.sh

log_success "âœ… CDN ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 2. ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • (ALB)
log_info "âš–ï¸ ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ì¤‘..."

# ALB ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > $PROJECT_DIR/setup-alb.sh << 'EOF'
#!/bin/bash

# Application Load Balancer ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

VPC_ID="vpc-xxxxxxxxx"
SUBNET_IDS="subnet-xxxxxxxxx,subnet-yyyyyyyyy"
SECURITY_GROUP_ID="sg-xxxxxxxxx"

echo "ALB ì„¤ì •ì„ ìœ„í•œ ì •ë³´..."
echo "VPC ID: $VPC_ID"
echo "Subnet IDs: $SUBNET_IDS"
echo "Security Group ID: $SECURITY_GROUP_ID"

# ALB ìƒì„±
aws elbv2 create-load-balancer \
    --name sceneforge-alb \
    --subnets $SUBNET_IDS \
    --security-groups $SECURITY_GROUP_ID \
    --scheme internet-facing \
    --type application

echo "ALBê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
EOF

chmod +x $PROJECT_DIR/setup-alb.sh

log_success "âœ… ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 3. Auto Scaling ì„¤ì •
log_info "ðŸ“ˆ Auto Scaling ì„¤ì • ì¤‘..."

# Auto Scaling ê·¸ë£¹ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > $PROJECT_DIR/setup-autoscaling.sh << 'EOF'
#!/bin/bash

# Auto Scaling ê·¸ë£¹ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

LAUNCH_TEMPLATE_ID="lt-xxxxxxxxx"
TARGET_GROUP_ARN="arn:aws:elasticloadbalancing:region:account:targetgroup/sceneforge-tg/xxxxxxxxx"

echo "Auto Scaling ê·¸ë£¹ ì„¤ì •..."
echo "Launch Template ID: $LAUNCH_TEMPLATE_ID"
echo "Target Group ARN: $TARGET_GROUP_ARN"

# Auto Scaling ê·¸ë£¹ ìƒì„±
aws autoscaling create-auto-scaling-group \
    --auto-scaling-group-name sceneforge-asg \
    --launch-template LaunchTemplateId=$LAUNCH_TEMPLATE_ID \
    --min-size 2 \
    --max-size 10 \
    --desired-capacity 2 \
    --target-group-arns $TARGET_GROUP_ARN \
    --vpc-zone-identifier "subnet-xxxxxxxxx,subnet-yyyyyyyyy"

# ìŠ¤ì¼€ì¼ë§ ì •ì±… ì„¤ì •
aws autoscaling put-scaling-policy \
    --auto-scaling-group-name sceneforge-asg \
    --policy-name scale-up-cpu \
    --scaling-adjustment 1 \
    --adjustment-type ChangeInCapacity \
    --cooldown 300

echo "Auto Scaling ê·¸ë£¹ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
EOF

chmod +x $PROJECT_DIR/setup-autoscaling.sh

log_success "âœ… Auto Scaling ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 4. ìºì‹± ì „ëžµ êµ¬í˜„
log_info "ðŸ’¾ ìºì‹± ì „ëžµ êµ¬í˜„ ì¤‘..."

# Redis ì„¤ì¹˜ ë° ì„¤ì •
if ! command -v redis-server &> /dev/null; then
    log_info "ðŸ“¦ Redis ì„¤ì¹˜ ì¤‘..."
    sudo apt install -y redis-server
    sudo systemctl start redis-server
    sudo systemctl enable redis-server
    log_success "âœ… Redis ì„¤ì¹˜ ì™„ë£Œ"
fi

# Redis ì„¤ì • ìµœì í™”
sudo tee -a /etc/redis/redis.conf > /dev/null << 'EOF'

# Performance optimizations
maxmemory 256mb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
EOF

sudo systemctl restart redis-server

# Node.js ìºì‹± ë¯¸ë“¤ì›¨ì–´ ìƒì„±
cat > $PROJECT_DIR/backend/middleware/cache.js << 'EOF'
const redis = require('redis');
const client = redis.createClient();

// ìºì‹± ë¯¸ë“¤ì›¨ì–´
const cacheMiddleware = (duration = 300) => {
    return (req, res, next) => {
        const key = `cache:${req.originalUrl}`;
        
        client.get(key, (err, data) => {
            if (err) {
                console.error('Redis ì˜¤ë¥˜:', err);
                return next();
            }
            
            if (data) {
                return res.json(JSON.parse(data));
            }
            
            // ì›ë³¸ ì‘ë‹µì„ ìºì‹œì— ì €ìž¥
            const originalSend = res.json;
            res.json = function(data) {
                client.setex(key, duration, JSON.stringify(data));
                originalSend.call(this, data);
            };
            
            next();
        });
    };
};

module.exports = { cacheMiddleware, client };
EOF

log_success "âœ… ìºì‹± ì „ëžµ êµ¬í˜„ ì™„ë£Œ"

# 5. MongoDB ì¸ë±ìŠ¤ ìµœì í™”
log_info "ðŸ—„ï¸ MongoDB ì¸ë±ìŠ¤ ìµœì í™” ì¤‘..."

# MongoDB ì¸ë±ìŠ¤ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > $PROJECT_DIR/backend/scripts/optimizeIndexes.js << 'EOF'
// MongoDB ì¸ë±ìŠ¤ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸

const mongoose = require('mongoose');

async function optimizeIndexes() {
    try {
        const db = mongoose.connection;
        
        // ì‚¬ìš©ìž ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
        await db.collection('users').createIndex({ "email": 1 }, { unique: true });
        await db.collection('users').createIndex({ "createdAt": -1 });
        
        // í”„ë¡œì íŠ¸ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
        await db.collection('projects').createIndex({ "userId": 1 });
        await db.collection('projects').createIndex({ "createdAt": -1 });
        await db.collection('projects').createIndex({ "title": "text", "synopsis": "text" });
        
        // ì½˜í‹° ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
        await db.collection('contes').createIndex({ "projectId": 1 });
        await db.collection('contes').createIndex({ "createdAt": -1 });
        await db.collection('contes').createIndex({ "status": 1 });
        
        console.log('âœ… MongoDB ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ');
    } catch (error) {
        console.error('âŒ ì¸ë±ìŠ¤ ìµœì í™” ì˜¤ë¥˜:', error);
    }
}

optimizeIndexes();
EOF

log_success "âœ… MongoDB ì¸ë±ìŠ¤ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 6. ì´ë¯¸ì§€ ì••ì¶• ë° ìµœì í™”
log_info "ðŸ–¼ï¸ ì´ë¯¸ì§€ ì••ì¶• ë° ìµœì í™” ì¤‘..."

# ì´ë¯¸ì§€ ìµœì í™” ë„êµ¬ ì„¤ì¹˜
if ! command -v imagemagick &> /dev/null; then
    sudo apt install -y imagemagick
fi

# ì´ë¯¸ì§€ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > $PROJECT_DIR/backend/scripts/optimizeImages.js << 'EOF'
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');

const uploadsDir = path.join(__dirname, '../uploads/images');

function optimizeImages() {
    if (!fs.existsSync(uploadsDir)) {
        console.log('ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.');
        return;
    }
    
    const files = fs.readdirSync(uploadsDir);
    const imageFiles = files.filter(file => 
        /\.(jpg|jpeg|png|gif)$/i.test(file)
    );
    
    console.log(`${imageFiles.length}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ìµœì í™”í•©ë‹ˆë‹¤...`);
    
    imageFiles.forEach(file => {
        const filePath = path.join(uploadsDir, file);
        const outputPath = path.join(uploadsDir, `optimized_${file}`);
        
        // ImageMagickì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìµœì í™”
        exec(`convert "${filePath}" -quality 85 -strip "${outputPath}"`, (error) => {
            if (error) {
                console.error(`ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: ${file}`, error);
            } else {
                console.log(`âœ… ${file} ìµœì í™” ì™„ë£Œ`);
                // ì›ë³¸ íŒŒì¼ ë°±ì—… í›„ ìµœì í™”ëœ íŒŒì¼ë¡œ êµì²´
                fs.renameSync(outputPath, filePath);
            }
        });
    });
}

optimizeImages();
EOF

log_success "âœ… ì´ë¯¸ì§€ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 7. PM2 í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ì„¤ì •
log_info "ðŸ”„ PM2 í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ì„¤ì • ì¤‘..."

# PM2 ì„¤ì • ì—…ë°ì´íŠ¸
cat > $PROJECT_DIR/ecosystem.config.js << 'EOF'
module.exports = {
  apps: [{
    name: 'sceneforge-backend',
    script: './backend/server.js',
    instances: 'max', // CPU ì½”ì–´ ìˆ˜ë§Œí¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    exec_mode: 'cluster',
    autorestart: true,
    watch: false,
    max_memory_restart: '1G',
    env: {
      NODE_ENV: 'development',
      PORT: 5001
    },
    env_production: {
      NODE_ENV: 'production',
      PORT: 5001
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_file: './logs/combined.log',
    time: true,
    log_date_format: 'YYYY-MM-DD HH:mm:ss Z',
    // í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ìµœì í™” ì„¤ì •
    kill_timeout: 5000,
    listen_timeout: 3000,
    max_restarts: 10,
    min_uptime: '10s'
  }]
};
EOF

log_success "âœ… PM2 í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ì„¤ì • ì™„ë£Œ"

# 8. Nginx ìºì‹± ì„¤ì •
log_info "ðŸŒ Nginx ìºì‹± ì„¤ì • ì¤‘..."

# Nginx ìºì‹± ì„¤ì • ì¶”ê°€
sudo tee /etc/nginx/conf.d/caching.conf > /dev/null << 'EOF'
# Nginx ìºì‹± ì„¤ì •

# ì •ì  íŒŒì¼ ìºì‹±
location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
    add_header Vary Accept-Encoding;
}

# API ì‘ë‹µ ìºì‹±
location /api {
    # ìºì‹œ ì„¤ì •
    proxy_cache_valid 200 302 10m;
    proxy_cache_valid 404 1m;
    proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
    proxy_cache_lock on;
    proxy_cache_lock_timeout 5s;
    
    # ìºì‹œ í‚¤ ì„¤ì •
    proxy_cache_key "$scheme$request_method$host$request_uri";
    
    # ìºì‹œ í—¤ë” ì¶”ê°€
    add_header X-Cache-Status $upstream_cache_status;
    
    proxy_pass http://localhost:5001;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
}

# Gzip ì••ì¶• ìµœì í™”
gzip on;
gzip_vary on;
gzip_min_length 1024;
gzip_proxied any;
gzip_comp_level 6;
gzip_types
    text/plain
    text/css
    text/xml
    text/javascript
    application/json
    application/javascript
    application/xml+rss
    application/atom+xml
    image/svg+xml;
EOF

# Nginx ì„¤ì • í…ŒìŠ¤íŠ¸ ë° ìž¬ì‹œìž‘
if sudo nginx -t; then
    sudo systemctl reload nginx
    log_success "âœ… Nginx ìºì‹± ì„¤ì • ì™„ë£Œ"
else
    log_error "âŒ Nginx ì„¤ì • ì˜¤ë¥˜"
fi

# 9. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜
log_info "ðŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜ ì¤‘..."

# New Relic ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
if ! command -v newrelic &> /dev/null; then
    log_info "ðŸ“¦ New Relic ì„¤ì¹˜ ì¤‘..."
    # New Relic ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (ë¼ì´ì„¼ìŠ¤ í‚¤ í•„ìš”)
    # curl -L https://download.newrelic.com/php_agent/release/newrelic-php5-{VERSION}.tar.gz | tar -C /tmp -zx
fi

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë„êµ¬ ì„¤ì¹˜
sudo apt install -y apache2-utils siege

log_success "âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ"

# 10. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
log_info "ðŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."

cat > $PROJECT_DIR/performance-test.sh << 'EOF'
#!/bin/bash

# SceneForge ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

echo "=== SceneForge ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ==="
echo "ì‹œê°„: $(date)"
echo ""

# 1. API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
echo "=== API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ ==="
ab -n 100 -c 10 http://localhost:5001/health
echo ""

# 2. ì›¹íŽ˜ì´ì§€ ë¡œë”© ì‹œê°„ í…ŒìŠ¤íŠ¸
echo "=== ì›¹íŽ˜ì´ì§€ ë¡œë”© ì‹œê°„ í…ŒìŠ¤íŠ¸ ==="
curl -s -w "ì‘ë‹µ ì‹œê°„: %{time_total}s\n" -o /dev/null http://localhost/
echo ""

# 3. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
echo "=== ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ==="
echo "CPU ì‚¬ìš©ë¥ : $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)%"
echo "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : $(free | grep Mem | awk '{printf "%.2f%%", $3/$2 * 100.0}')"
echo "ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : $(df / | tail -1 | awk '{print $5}')"
echo ""

# 4. PM2 í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
echo "=== PM2 í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ==="
pm2 list
echo ""

# 5. Redis ìºì‹œ ìƒíƒœ
echo "=== Redis ìºì‹œ ìƒíƒœ ==="
redis-cli info memory | grep used_memory_human
echo ""
EOF

chmod +x $PROJECT_DIR/performance-test.sh

log_success "âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# 11. ìµœì í™” ìƒíƒœ í™•ì¸
log_info "ðŸ” ìµœì í™” ìƒíƒœ í™•ì¸ ì¤‘..."

# Redis ìƒíƒœ
if systemctl is-active --quiet redis-server; then
    log_success "   Redis: ì‹¤í–‰ ì¤‘"
else
    log_error "   Redis: ì¤‘ì§€ë¨"
fi

# PM2 í´ëŸ¬ìŠ¤í„° ìƒíƒœ
if pm2 list | grep -q "sceneforge-backend"; then
    INSTANCE_COUNT=$(pm2 list | grep "sceneforge-backend" | wc -l)
    log_success "   PM2 í´ëŸ¬ìŠ¤í„°: $INSTANCE_COUNT ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰ ì¤‘"
else
    log_error "   PM2 í´ëŸ¬ìŠ¤í„°: ì‹¤í–‰ë˜ì§€ ì•ŠìŒ"
fi

# Nginx ìºì‹± ì„¤ì • í™•ì¸
if grep -q "proxy_cache" /etc/nginx/conf.d/caching.conf; then
    log_success "   Nginx ìºì‹±: ì„¤ì •ë¨"
else
    log_warning "   Nginx ìºì‹±: ì„¤ì •ë˜ì§€ ì•ŠìŒ"
fi

log_success "ðŸŽ‰ SceneForge ì„±ëŠ¥ ìµœì í™” ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
log_info "ðŸ“‹ ìµœì í™” ì„¤ì • ì •ë³´:"
log_info "   CDN ì„¤ì •: $PROJECT_DIR/setup-cloudfront.sh"
log_info "   ë¡œë“œ ë°¸ëŸ°ì„œ: $PROJECT_DIR/setup-alb.sh"
log_info "   Auto Scaling: $PROJECT_DIR/setup-autoscaling.sh"
log_info "   ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: $PROJECT_DIR/performance-test.sh"
log_info "   Redis ìƒíƒœ: systemctl status redis-server"
log_info "   PM2 ìƒíƒœ: pm2 list" 